{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e96bdbc5",
   "metadata": {},
   "source": [
    "#  Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f78e0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "import pickle\n",
    "import nltk\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68a95d3",
   "metadata": {},
   "source": [
    "# # Reading CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354e8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train.csv into a DataFrame, assigned to news_dataset\n",
    "news_dataset= pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae86bd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the first 5 rows of a DataFrame as default\n",
    "#here \"0\" means REAL NEWS & \"1\" mean FAKE NEWS according to dataset\n",
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3ff7677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints no. of rows and columns of a DataFrame\n",
    "news_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b7538f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking NULL values in dataset\n",
    "#returns the number of missing values in the data set\n",
    "news_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84bfea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas DataFrame dropna() function is used to remove rows and columns with Null/NaN values.\n",
    "news_dataset=news_dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a614d606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "title     0\n",
       "author    0\n",
       "text      0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking again the Null values\n",
    "news_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddcc9796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after dropping Null values\n",
    "news_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f73dfa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here text column is assigned to x and label column assigned to y\n",
    "x= news_dataset['text']\n",
    "y= news_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68798b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        House Dem Aide: We Didn’t Even See Comey’s Let...\n",
       "1        Ever get the feeling your life circles the rou...\n",
       "2        Why the Truth Might Get You Fired October 29, ...\n",
       "3        Videos 15 Civilians Killed In Single US Airstr...\n",
       "4        Print \\nAn Iranian woman has been sentenced to...\n",
       "                               ...                        \n",
       "20795    Rapper T. I. unloaded on black celebrities who...\n",
       "20796    When the Green Bay Packers lost to the Washing...\n",
       "20797    The Macy’s of today grew from the union of sev...\n",
       "20798    NATO, Russia To Hold Parallel Exercises In Bal...\n",
       "20799      David Swanson is an author, activist, journa...\n",
       "Name: text, Length: 18285, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X contains the text Column\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9b0da82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "20795    0\n",
       "20796    0\n",
       "20797    0\n",
       "20798    1\n",
       "20799    1\n",
       "Name: label, Length: 18285, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y contains the Label column\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd29c7b",
   "metadata": {},
   "source": [
    "#  Cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff5046",
   "metadata": {},
   "source": [
    "# 1. Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "590ea02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuations from the String  \n",
    "s = \"!</> hello there$$ </>^t!!!h%%i&&%$s@@@^^^&&!& </>*is@# fake&&\\ news@@@##%^ ^&dete!@ction# %%$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4410153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using re module (Regular Expression)\n",
    "import re\n",
    "s = re.sub(r'[^\\w\\s]','',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eea8485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hello there this is fake news detection \n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd7a9a9",
   "metadata": {},
   "source": [
    "# 2. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5e24628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shiva\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Downloading nltk data\n",
    "#NLTK data package includes a pre-trained Punkt tokenizer for English.\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a03baf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'there', 'this', 'is', 'Fake', 'news', 'Detection', 'Project']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(\"Hello there this is Fake news Detection Project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acb4558",
   "metadata": {},
   "source": [
    "# 3. StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "340a744f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#corpus is a large and structured set of texts.\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69394218",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Covid-19 pandemic has impacted many countries and what it did to economy is very stressful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89e8e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(sentence)\n",
    "words = [w for w in words if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecddb257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Covid-19',\n",
       " 'pandemic',\n",
       " 'impacted',\n",
       " 'many',\n",
       " 'countries',\n",
       " 'economy',\n",
       " 'stressful']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b496e40",
   "metadata": {},
   "source": [
    "# 4. Lemmatization (Superior than Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0853240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "input_str=\"been had done languages cities mice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a50bc1a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'actor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-48e338d4550d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mactor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'actor' is not defined"
     ]
    }
   ],
   "source": [
    "actor,acting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82226753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "been\n",
      "had\n",
      "done\n",
      "language\n",
      "city\n",
      "mouse\n"
     ]
    }
   ],
   "source": [
    "#Tokenize the sentence\n",
    "input_str=nltk.word_tokenize(input_str)\n",
    "\n",
    "#Lemmatize each word\n",
    "for word in input_str:\n",
    "    print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad6e756",
   "metadata": {},
   "source": [
    "# Let's Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e235df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "for index,row in news_dataset.iterrows():\n",
    "    filter_sentence = ''\n",
    "    \n",
    "    sentence = row['text']\n",
    "    sentence = re.sub(r'[^\\w\\s]','',sentence) #cleaning\n",
    "    \n",
    "    words = nltk.word_tokenize(sentence) #tokenization\n",
    "    \n",
    "    words = [w for w in words if not w in stop_words]  #stopwords removal\n",
    "    \n",
    "    for word in words:\n",
    "        filter_sentence = filter_sentence + ' ' + str(lemmatizer.lemmatize(word)).lower()\n",
    "        \n",
    "    news_dataset.loc[index,'text'] = filter_sentence  #.loc attribute to access a particular cell in the given Dataframe using the index and column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eeac3524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>house dem aide we didnt even see comeys lette...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>ever get feeling life circle roundabout rathe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>why truth might get you fired october 29 2016...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>videos 15 civilians killed in single us airst...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>print an iranian woman sentenced six year pri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0   house dem aide we didnt even see comeys lette...      1  \n",
       "1   ever get feeling life circle roundabout rathe...      0  \n",
       "2   why truth might get you fired october 29 2016...      1  \n",
       "3   videos 15 civilians killed in single us airst...      1  \n",
       "4   print an iranian woman sentenced six year pri...      1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eec24f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here text column is assigned to x and label column assigned to y\n",
    "x= news_dataset['text']\n",
    "y= news_dataset['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970aaa69",
   "metadata": {},
   "source": [
    "# Applying NLP Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97ea3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03abea5",
   "metadata": {},
   "source": [
    "# Splitting data in Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b772d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,stratify=y,random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b864c14",
   "metadata": {},
   "source": [
    "# TF-iDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a62b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfvect = TfidfVectorizer(stop_words='english',max_df=0.7)\n",
    "tfid_x_train = tfvect.fit_transform(x_train)\n",
    "tfid_x_test = tfvect.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "268df97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 137752)\t0.036976566496463206\n",
      "  (0, 85271)\t0.044710881314325567\n",
      "  (0, 97113)\t0.04030211073922633\n",
      "  (0, 58928)\t0.014749977900084315\n",
      "  (0, 45489)\t0.03668860481133672\n",
      "  (0, 48102)\t0.03315794592722513\n",
      "  (0, 80105)\t0.01821718492854408\n",
      "  (0, 86625)\t0.028903281294887617\n",
      "  (0, 60794)\t0.025231842790051612\n",
      "  (0, 25117)\t0.03650350446878842\n",
      "  (0, 148593)\t0.024259607649512398\n",
      "  (0, 128167)\t0.029162438702899342\n",
      "  (0, 111583)\t0.017868789204711265\n",
      "  (0, 6907)\t0.01890303291187917\n",
      "  (0, 131394)\t0.032762013888570245\n",
      "  (0, 28916)\t0.0396031983562183\n",
      "  (0, 53380)\t0.018860967366340815\n",
      "  (0, 51022)\t0.02592417006796663\n",
      "  (0, 40999)\t0.03138339156523\n",
      "  (0, 145785)\t0.02179580841555102\n",
      "  (0, 73253)\t0.037648202749699926\n",
      "  (0, 10061)\t0.03205902925912119\n",
      "  (0, 61749)\t0.02290847773546937\n",
      "  (0, 72933)\t0.030866461452400077\n",
      "  (0, 61678)\t0.03573036766937597\n",
      "  :\t:\n",
      "  (14627, 119329)\t0.00900254162854916\n",
      "  (14627, 95271)\t0.016056332449802133\n",
      "  (14627, 79765)\t0.032622444999008425\n",
      "  (14627, 49123)\t0.01200159021766943\n",
      "  (14627, 135705)\t0.015313528686887358\n",
      "  (14627, 51425)\t0.11980230710315579\n",
      "  (14627, 36140)\t0.07912631067679814\n",
      "  (14627, 145812)\t0.032478076254954864\n",
      "  (14627, 145465)\t0.05835041978806136\n",
      "  (14627, 48514)\t0.053707169214773136\n",
      "  (14627, 45594)\t0.017442545760992596\n",
      "  (14627, 146210)\t0.00996766210401498\n",
      "  (14627, 43422)\t0.022851397723549428\n",
      "  (14627, 118166)\t0.039845963167444196\n",
      "  (14627, 111742)\t0.013147148268438727\n",
      "  (14627, 57675)\t0.010925050102449083\n",
      "  (14627, 75836)\t0.019576980139522304\n",
      "  (14627, 134518)\t0.011846149377203869\n",
      "  (14627, 79918)\t0.023533385973356417\n",
      "  (14627, 136465)\t0.02391763951427155\n",
      "  (14627, 120184)\t0.03642200628399386\n",
      "  (14627, 57483)\t0.010146758168179035\n",
      "  (14627, 145948)\t0.009147670782898397\n",
      "  (14627, 129684)\t0.018978437401285096\n",
      "  (14627, 146618)\t0.013300655391439516\n"
     ]
    }
   ],
   "source": [
    "print(tfid_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b1ea3",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "793bf00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.99%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score on training data\n",
    "pac= PassiveAggressiveClassifier(max_iter= 50)\n",
    "clf = CalibratedClassifierCV(pac)\n",
    "clf.fit(tfid_x_train,y_train)\n",
    "X_train_prediction= clf.predict(tfid_x_train)\n",
    "score = accuracy_score(y_train,X_train_prediction)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e2e66b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.58%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score on test data\n",
    "pac= PassiveAggressiveClassifier(max_iter= 50)\n",
    "clf = CalibratedClassifierCV(pac)\n",
    "clf.fit(tfid_x_train,y_train)\n",
    "X_test_prediction= clf.predict(tfid_x_test)\n",
    "score = accuracy_score(y_test,X_test_prediction)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eeacc4",
   "metadata": {},
   "source": [
    "# Pipelining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbf0e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('tfidf',TfidfVectorizer(stop_words='english')),\n",
    "                    ('PacModel', CalibratedClassifierCV(pac))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d356c79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(stop_words='english')),\n",
       "                ('PacModel',\n",
       "                 CalibratedClassifierCV(base_estimator=PassiveAggressiveClassifier(max_iter=50)))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5bea3bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.77%\n"
     ]
    }
   ],
   "source": [
    "score= pipeline.score(x_test,y_test)\n",
    "print(f'Accuracy: {round(score*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea5e8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= pipeline.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "328b3327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(pred[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8e94778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16924    1\n",
       "13869    0\n",
       "4264     0\n",
       "9200     1\n",
       "14912    0\n",
       "        ..\n",
       "20455    1\n",
       "4495     0\n",
       "6712     0\n",
       "4988     0\n",
       "4329     1\n",
       "Name: label, Length: 3657, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3d36a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      2072\n",
      "           1       0.96      0.96      0.96      1585\n",
      "\n",
      "    accuracy                           0.97      3657\n",
      "   macro avg       0.97      0.97      0.97      3657\n",
      "weighted avg       0.97      0.97      0.97      3657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "668bca41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2015   57]\n",
      " [  61 1524]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce44bb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Clfpac.pkl', 'wb') as handle:\n",
    "    pickle.dump(pipeline, handle, protocol= pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6805eb00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
